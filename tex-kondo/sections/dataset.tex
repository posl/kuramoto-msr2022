\section{Study Design}
\label{sec:design}

% In this section, we describe the data collection process and 
% the overview of the collected dataset. 
In this section, we describe our study design. 
In particular, we describe research questions and 
the data collection process.

\subsection{Research Questions}
\label{sec:rqs}

To clarify the characteristics of 
the visual issue reports,
% with images and movies, 
% we executed an initial analysis 
% in our dataset. 
% Specifically, 
we addressed the following 
two research questions. 
\begin{itemize}
	\item[RQ1:] \textbf{\RQone{}}\\
	% The feature to share movies on GitHub 
	% is still new. 
	% Hence, we suppose that using visualization 
	% is not popular for developers. 
	% In this RQ, we counted the number of 
	% issues that use either issues or movies 
	% to clarify whether using visualization 
	% is popular. 
	We suppose visual issue reports provide 
	more information than the other issue reports. 
	Consequently, developers could discuss the details and 
	result in active discussions. 
	In this RQ, we clarify whether this assumption is true. 
	We measured the activity in terms of 
	the first response time, 
	the number of comments, and 
	the number of words. 
	\item[RQ2:] \textbf{\RQtwo{}}\\
	% We suppose that developers use visualization 
	% in particular issues. 
	% For example, developers may use visualization 
	% to share the way to reproduce bugs. 
	% In this RQ, we clarify the differences 
	% between the issues with and without 
	% visualization. 
	Zimmermann~\et~\citep{zimmermann2010TSE} reported that
	issue reports occasionally have missing or incorrect steps 
	to reproduce bugs, 
	while GitHub argued that visual issue reports easily 
	provide the steps~\citep{github-video-blog}. 
	Hence, we suppose that visual issue reports could be 
	resolved more quickly than the other issue reports 
	because of the sufficient information. 
	In this RQ, we clarify whether this assumption is true. 
\end{itemize}

\subsection{Context Selection}
We collected the data from the issues of 
the publicly available repositories on GitHub. 
We first select the repositories based on the following conditions:
\begin{itemize}
	\item the number of stars $\geq$ 10
	\item the number of issues $\geq$ 1
	\item the latest commit is in 2021
\end{itemize}
We used the number of stars for retrieving the repositories 
in which the owner may communicate with other developers and 
discard repositories developed by only the owner. 
In addition, we used the date of the latest commit 
because the major release of the feature is in 2021. 
Beforehand, the feature was the beta version. 
The number of the repositories that meet 
the conditions is 289,115. 
We randomly selected 4,173 repositories from them 
due to the execution time to collect issues. 
This number is less than 2\% of all repositories. 
However, the number of resolved issues 
in these repositories is already 770,656. 
We discuss the threat to validity of 
this process in \sec{sec:limitation}. 
This process was conducted from November 2021 to December 2021.

\input{figures/data-collection-overview}

\subsection{Data Collection}
\fig{fig:data-collection-overview} shows an overview of 
the data collection process. 
We first collect issue report data with \texttt{PyGitHub}\masa{add citation} 
that internally execute GitHub API. 
Next, we download movies and images from GitHub.
% since the collected issue data contain only the file names of 
% images and movies. The attached images and movies are 
% transformed into URLs and put in the text of issues as the markdown format. 
%The following URL is an example to download mp4 files. 
GitHub transformed the images and movies into URLs such as:
\kashiwa{DO-YU-IMI???}
\masa{to kashiwa: how about this?}
\begin{quote}
	% https://user-images.githubusercontent.com/XXX.mp4
	https://user-images.githubusercontent.com/file-name.mp4
	\\\kashiwa{XXXX HA YADA. It looks a template}
\masa{to kashiwa: how about this?}
\end{quote}
Hence, we used the regular expression 
to download the images and movies. 
%\noindent{}
%where, the part of XXX consists of alphanumeric, ``/'', and ``-''.
Consequently, we downloaded 33,079 images and 3,819 movies.\masa{to kuramoto: i wrote these numbers. are the numbers correct?} 

We classified the issues into three categories based on 
whether they have images and movies. 
\tab{tab:issue-category} shows the number of issues for each category. 
Note that issues often have both images and movies. 
These issues are included in both $Img$ and $Mov$ categories. 
Thus, the total number of downloaded issues is different from 
the sum of \#issues in \masa{Table X}\masa{Kashiwa-sensei wrote this right? I highlight the unknown table number}. 

\input{tables/issue-category}

% \input{tables/issue-ex}
% We extract a part of the retrieved issues in \tab{tab:example-dataset}. 
% Each row corresponds to the values of the attributes of an issue. 

\subsection{Metrics Computation}
\input{tables/issue-attr}
We retrieved the attributes from the collected issues 
that are the data in the database. \tab{tab:issue-attr} shows the eight attributes 
retrieved from the issues. 
$IssueResolvedTime$, $FirstCommentTime$,
and $IssueCreatedYear$ can be extracted from issue reports. 

On the contrary, $\#chars$, $\#imgs$, $\#movs$, and $Words$ need several pre-processes from issue reports. 
% It should be noted that we computed these attributes 
% on the description of issue reports. 
% Hence, we computed these attributes on neither 
% the title nor the comments on the issue reports. 
It should be noted that issue reports consist of three contents: 
title, description, and comments. 
We computed $\#chars$, $\#imgs$, $\#movs$, and $Words$ based on the description only. 
Hence, we used neither the title nor the comments 
to compute these attributes.
% It should be noted that we converted the first description of 
% issues into these four attribute values and 
% ignore the comments and the title.
\kashiwa{I dont get this}
\masa{to kashiwa: how about this?}

Hence, we prepared the regular expression for this URL and 
count the appearances of images and movies as $\#imgs$ and $\#movs$. 
The identification of images and movies is based on the extension of 
the URLs. 
Specifically, we used png, PNG, jpg, JPG, and jpeg as 
the extensions for images and 
gif, GIF, mp4, MP4, and mov as the extensions for movies.

We counted the number of characters as $\#chars$ and 
stored the words as $Words$ for all issues. 
In this process, if the description of the issue 
includes the URL, we exclude it from the description, 
and convert all issues into $\#chars$ and $Words$.
% For the issues that include the URL, we excluded them and 
% counted the number of words as $\#words$. 
% In addition, we counted the number of characters as $\#chars$. 

We noticed that some $IssueResolvedTime$ values are less than zero. 
We decided that these values are invalid and the issues having 
these values are excluded from the dataset. 
In addition, to study the impact of movies and images on 
the communication in issues, 
we excluded issues that resolved less than 30 secs. 
This is because this issue resolution time is too short 
to communicate with each other. 
Specifically, we only retrieved the issues that meet 
the condition: $30\ sec \leq IssueResolvedTime \leq 1\ year$.
The number of issues that meet this condition is 711,160 (92.23\%).